{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7091d155-be77-4bd6-9ff2-fb69afa41777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import IPython\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, BatchNormalization, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import (\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "\n",
    "from functions.normalize_images import normalize_images\n",
    "from functions.display_images import display_images\n",
    "from functions.load_images import load_images\n",
    "from functions.create_dir import create_dir\n",
    "from functions.format_filename import format_filename\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))\n",
    "from hidden import MLFLOW_RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aea5dc-9b37-484f-8d92-6e8e53e50eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for random operations.\n",
    "random.seed(422)\n",
    "tf.random.set_seed(422)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8348b5-f952-4ed2-8d7d-8b081ca0189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers le répertoire racine\n",
    "root_path = \"./data/\"\n",
    "raw_path = os.path.join(root_path, \"raw\")\n",
    "proc_path = os.path.join(root_path, \"proc\")\n",
    "\n",
    "# Créer les répertoires train et test\n",
    "train_path = os.path.join(proc_path, \"train\")\n",
    "val_path = os.path.join(proc_path, \"val\")\n",
    "test_path = os.path.join(proc_path, \"test\")\n",
    "\n",
    "create_dir(train_path)\n",
    "create_dir(val_path)\n",
    "create_dir(test_path)\n",
    "\n",
    "# Liste des classes (yes, no)\n",
    "classes = [\"yes\", \"no\"]\n",
    "\n",
    "file_mapping = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "# Pour chaque classe\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(raw_path, class_name)\n",
    "    images = os.listdir(class_path)\n",
    "\n",
    "    # Mélanger aléatoirement les images\n",
    "    random.shuffle(images)\n",
    "\n",
    "    # Calculer la séparation des données (60/20/20)\n",
    "    val_split_index = int(0.6 * len(images))\n",
    "    test_split_index = int(0.8 * len(images))\n",
    "\n",
    "    # Diviser les données en ensembles d'entraînement et de test\n",
    "    train_images = images[:val_split_index]\n",
    "    val_images = images[val_split_index:test_split_index]\n",
    "    test_images = images[test_split_index:]\n",
    "\n",
    "    # Créer les répertoires de classe dans les ensembles d'entraînement et de test\n",
    "    train_class_path = os.path.join(train_path, class_name)\n",
    "    val_class_path = os.path.join(val_path, class_name)\n",
    "    test_class_path = os.path.join(test_path, class_name)\n",
    "\n",
    "    create_dir(train_class_path)\n",
    "    create_dir(val_class_path)\n",
    "    create_dir(test_class_path)\n",
    "\n",
    "    for dataset_name, dataset_images, dataset_class_path in [\n",
    "        (\"train\", train_images, train_class_path),\n",
    "        (\"val\", val_images, val_class_path),\n",
    "        (\"test\", test_images, test_class_path),\n",
    "    ]:\n",
    "        for image in dataset_images:\n",
    "            src = os.path.join(class_path, image)\n",
    "            dst = os.path.join(dataset_class_path, format_filename(counter))\n",
    "            shutil.copy(src, dst)\n",
    "            file_mapping += [\n",
    "                {\n",
    "                    \"raw_img_path\": src,\n",
    "                    \"proc_img_path\": dst,\n",
    "                    \"class_name\": class_name,\n",
    "                    \"dataset_name\": dataset_name,\n",
    "                }\n",
    "            ]\n",
    "            counter += 1\n",
    "\n",
    "df = pd.DataFrame.from_records(file_mapping)\n",
    "df.to_csv(os.path.join(root_path, \"file_mapping.csv\"), index=False, header=True)\n",
    "df.groupby([\"dataset_name\", \"class_name\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9060f81-6eb7-4411-b674-8cb0c5e7eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_images(train_path)\n",
    "X_val, y_val = load_images(val_path)\n",
    "X_test, y_test = load_images(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f32bd28-5b11-4cdf-a023-33c8db976c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation de la fonction avec X et y provenant du train\n",
    "display_images(X_train, y_train, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf8f53b-f0a4-4ee2-8592-e8a815cadcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation de la fonction avec X (images non normalisées) et la taille cible\n",
    "target_size = (224, 224)\n",
    "X_train_norm = normalize_images(X_train, target_size)\n",
    "X_val_norm = normalize_images(X_val, target_size)\n",
    "X_test_norm = normalize_images(X_test, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c42379-148d-4ddb-9714-2829c1bb8951",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_images(X_train_norm, y_train, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f71b0a-0659-41c4-849e-2ca4c7a61ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle VGG-16 pré-entraîné (ne pas inclure la couche dense finale)\n",
    "base_model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NUM_CLASSES, activation=\"sigmoid\"))\n",
    "\n",
    "# figer les poids du VGG\n",
    "model.layers[0].trainable = False\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=RMSprop(learning_rate=1e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Afficher la structure du modèle\n",
    "model.summary()\n",
    "\n",
    "# Créer un générateur d'images pour la data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.01,\n",
    "    height_shift_range=0.01,\n",
    "    zoom_range=0.05,\n",
    "    shear_range=0.01,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    ")\n",
    "\n",
    "# Ajuster le générateur aux données d'entraînement\n",
    "datagen.fit(X_train_norm)\n",
    "\n",
    "# Créer un callback d'arrêt anticipé\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # Surveiller la perte sur l'ensemble de validation\n",
    "    patience=10,  # Arrêter l'entraînement si la perte ne diminue pas pendant 3 époques consécutives\n",
    "    # Restaurer les poids du modèle aux meilleurs atteints pendant l'entraînement\n",
    "    restore_best_weights=True,\n",
    "    verbose=1,  # Afficher des messages lors de l'arrêt anticipé\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Entraîner le modèle avec l'augmentation de données\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train_norm, y_train, batch_size=BATCH_SIZE),\n",
    "    epochs=50,\n",
    "    steps_per_epoch=len(X_train_norm) // BATCH_SIZE,\n",
    "    validation_data=(X_val_norm, y_val),\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "model.evaluate(X_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a8d87-98c1-45f1-9ae6-c32403488f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43352f4b-d614-4935-af6f-6996ed3181ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model performance\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs_range = range(1, len(history.epoch) + 1)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(epochs_range, acc, label=\"Train Set\")\n",
    "plt.plot(epochs_range, val_acc, label=\"Val Set\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Model Accuracy\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.yscale(\"log\")\n",
    "plt.plot(\n",
    "    epochs_range,\n",
    "    loss,\n",
    "    label=\"Train Set\",\n",
    ")\n",
    "plt.plot(epochs_range, val_loss, label=\"Val Set\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Model Loss\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d3a8b2-f0d8-4a2e-b2ff-7fb3e503a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc74e1-e598-42a8-bf29-45b048466974",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred_prob > 0.5).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15423065-ff68-401d-b6fe-668573d662b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644056d0-0a83-4fcb-accb-4c47715ed349",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affec31e-99ac-44e5-abfd-82c3203a5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_ok_y_test = y_test[y_pred != y_test]\n",
    "not_ok_X_test = X_test[y_pred != y_test]\n",
    "\n",
    "display_images(not_ok_X_test, not_ok_y_test, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c84886-0fd2-461f-a8a7-8ac2bdeb0268",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"recall = \", recall_score(y_test, y_pred))\n",
    "print(\"precision = \", precision_score(y_test, y_pred))\n",
    "print(\"f1 score = \", f1_score(y_test, y_pred))\n",
    "print(\"rocauc = \", roc_auc_score(y_test, y_pred_prob))\n",
    "\n",
    "# Calculate ROC curve metrics\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color=\"blue\", lw=2, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", linestyle=\"--\", lw=2, label=\"Random\")\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2337b0-b351-4adb-83d6-1c9dcb5e5535",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d77f6a7-3cec-4e5d-ad54-466be7bd3fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as keras\n",
    "model.save(\"brain_tumor_detector.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90d83d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"NeuroApp\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"epochs\", len(history.epoch))\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"learning_rate\", 1e-4)\n",
    "    mlflow.log_param(\"dropout_rate\", 0.5)\n",
    "    mlflow.log_param(\"num_classes\", NUM_CLASSES)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"val_loss\", val_loss[-1])\n",
    "    mlflow.log_metric(\"val_accuracy\", val_acc[-1])\n",
    "    mlflow.log_metric(\"test_loss\", model.evaluate(X_test_norm, y_test, verbose=0)[0])\n",
    "    mlflow.log_metric(\n",
    "        \"test_accuracy\", model.evaluate(X_test_norm, y_test, verbose=0)[1]\n",
    "    )\n",
    "    mlflow.log_metric(\"recall\", recall_score(y_test, y_pred))\n",
    "    mlflow.log_metric(\"precision\", precision_score(y_test, y_pred))\n",
    "    mlflow.log_metric(\"f1_score\", f1_score(y_test, y_pred))\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc_score(y_test, y_pred_prob))\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.keras.log_model(model, \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7e5d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(MLFLOW_RUN)\n",
    "\n",
    "predicted_test = loaded_model.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acdf962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize predicted_test\n",
    "predicted_test = (predicted_test > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct = 0\n",
    "for i in range(len(predicted_test)):\n",
    "    if predicted_test[i] == int(y_test[i]):\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(predicted_test)\n",
    "\n",
    "print(f\"Prediction accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Plot X_test_norm\n",
    "num_images = len(X_test_norm)\n",
    "rows = int(\n",
    "    np.ceil(num_images / 5.0)\n",
    ")  # Use np.ceil to round up to the nearest whole number\n",
    "fig, axes = plt.subplots(rows, 5, figsize=(15, rows * 3))\n",
    "axes = axes.ravel()  # Flatten the axes array\n",
    "\n",
    "# Hide axes for unused subplots\n",
    "for ax in axes[num_images:]:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "for i, image in enumerate(X_test_norm):\n",
    "    axes[i].imshow(image, cmap=\"gray\")\n",
    "    axes[i].axis(\"off\")\n",
    "    if predicted_test[i] == int(y_test[i]):\n",
    "        axes[i].set_title(\n",
    "            f\"Predicted: {predicted_test[i][0]}, Actual: {y_test[i]}\", color=\"green\"\n",
    "        )\n",
    "    else:\n",
    "        axes[i].set_title(\n",
    "            f\"Predicted: {predicted_test[i][0]}, Actual: {y_test[i]}\", color=\"red\"\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e6ba69-11b2-4b15-a2c9-4e65f28c6c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
